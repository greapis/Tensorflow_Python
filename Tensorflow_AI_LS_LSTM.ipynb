{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/89qiigmDXiH+lqIulbVt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greapis/Tensorflow_Python/blob/main/Tensorflow_AI_LS_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1. Library\n",
        "\n",
        " - Keras에서 일부 전처리된 형태의 IMDB Data 제공\n",
        " - Keras - sklearn이 서로 호환되지 않기 때문에 \"KerasClassifier\" 필요 : 이 부분은 Tensorflow가 업데이트되면서 변동되어서 확인 필요"
      ],
      "metadata": {
        "id": "m_IMUTJhxKX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries\n",
        "  # Keras abd Sklearn libraries\n",
        "    # Importing KerasClassifier Library : Keras vs Sklearn 호환성 이슈 해결\n",
        "\n",
        "\n",
        "# IMDB Datasets 불러오기 from Keras\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "# 리뷰 길이 맞추기\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Making Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
        "\n",
        "# Keras model - (래핑) - sklearn이 이해할 수 있는 형태로 변환\n",
        "# Install scikeras package : \"scikeras\" 설치 필요\n",
        "!pip install scikeras\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier  : 최신 TensorFlow(특히 2.12 이상)에서는 tensorflow.keras.wrappers.scikit_learn 모듈이 더 이상 제공되지 않습니다.\n",
        "\n",
        "# Importing GreidSearch\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Caculating Accuracy\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "jTCtkkvWxJE-",
        "outputId": "b95120ce-a4cf-4be5-ce1e-509698f078c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikeras in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from scikeras) (3.8.0)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from scikeras) (1.7.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.16.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (24.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras>=3.2.0->scikeras) (4.14.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier :\n",
        "\n",
        "\n",
        "*  최신 TensorFlow(특히 2.12 이상)에서는 tensorflow.keras.wrappers.scikit_learn 모듈이 더 이상 제공되지 않습니다.\n",
        "*  과거에는 Keras가 scikit-learn과의 호환성을 위해 이 모듈을 제공했지만, 이제는 공식적으로 지원을 중단했으며, 이 기능은 별도의 패키지로 분리되었습니다\n",
        "\n",
        "\n",
        "\n",
        "*   scikeras 사용 : 대안으로 scikeras라는 패키지를 사용할 수 있습니다.\n",
        "다음처럼 임포트하면 됩니다:\n",
        "*   from scikeras.wrappers import KerasClassifier 또는 from scikeras.wrappers import KerasRegressor\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CXiquR5Boqw6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2. Data 전처리\n",
        "\n",
        " - 리뷰 데이터 형태를 '숫자'로 변환 : ex[1, 5, 35, 6,... ,532]\n",
        " - label : Positive(1), Negative(0)"
      ],
      "metadata": {
        "id": "-3IM9CRdxt9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading datas and 전처리\n",
        "\n",
        "\n",
        "# words dictionary : 상위 10000개 까지 단어만 사용(커트라인)\n",
        "# 문장 길이(maxien) : 256단어 길이로 제한 통일\n",
        "num_words = 10000\n",
        "maxlen = 256\n",
        "\n",
        "\n",
        "# Seperating Learning Data // Test Data\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=num_words)\n",
        "\n",
        "\n",
        "# Making equal the sentence length\n",
        "X_train = pad_sequences(X_train, maxlen=maxlen) # Corrected keyword argument\n",
        "X_test = pad_sequences(X_test, maxlen=maxlen) # Corrected keyword argument"
      ],
      "metadata": {
        "id": "7eXllPIQloNT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3. Learning and Validation\n",
        "\n",
        " - 모델을 함수로 정의\n",
        " - 기존과 달리 모델을 함수로 정의(def로 함수 정의 사용)\n",
        " - Grid Search에서 재사용하기 위해 함수로 정의 사용\n",
        " - 함수로 3가지 Layer 정의 사용(Embedding Layer, LSTM Layer. Fully Connected Layer)"
      ],
      "metadata": {
        "id": "ofKqyYn63eda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 구축 // Function definition\n",
        "\n",
        "\n",
        "# Model을 function으로 정의 : hyperparameter를 튜닝하기 위해 // Gridsearch에서 재사용\n",
        "\n",
        "def build_model(unit = 64):\n",
        "    model = Sequential()\n",
        "    # embedding layer(단어(text)를 숫자(scalar)로 그리고 다시 숫자(128차원 Vector로))\n",
        "    model.add(Embedding(input_dim=num_words, output_dim=128, input_length=maxlen))\n",
        "    # LSTM Layer\n",
        "    model.add(LSTM(units))\n",
        "    # Fully Connected Layer (Number of Neuron = 1(결과값이 1개 필요해서 : 1 or 0),  Sigmoid activation function : 0~1사이의 값으로 변환)\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # 최적화 : adam사용, 손실함수 : binary_crossentropy, 평가지표 : accuracy\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "24GY74dK1-yt"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4hgT2-q7cBmf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning and Validation v2\n",
        "\n",
        "\n",
        "# Keras model을 scikit-learn 포맷으로 래핑? : 최신 TensorFlow(특히 2.12 이상)에서는 tensorflow.keras.wrappers.scikit_learn 모듈이 더 이상 제공 안됨\n",
        "#    설치된 \"scikeras\" library 사용(from scikeras.wrappers import KerasClassifier)\n",
        "\n",
        "model = KerasClassifier(build_fn=build_model, verbose=1)\n",
        "  #  verbose = 0 : 훈련 과정 안 보임 // verbose = 1 : 훈련 과정 표시\n",
        "\n",
        "# Defining Hyperparameter Grid\n",
        "param_grid = {\n",
        "    'units': [32, 64],\n",
        "    'batch_size': [16, 32],\n",
        "    'epochs': [2,3,4]\n",
        "}\n",
        "\n",
        "\n",
        "# CV(Cross Validation) + Tuning\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
        "    # model을 esimator에 집어 넣고 실험, \"cv=3\"은 3-Folde Cross Validation 실행\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Optimal Parameter 출력 (최적의 hypaerparameter 조합 실행)\n",
        "print(\"Best Parameters:\", grid_result.best_params_)\n",
        "print(\"Best Cross-Validation Accuracy:\", grid_result.best_score_)"
      ],
      "metadata": {
        "id": "eMy50N2X4MeI",
        "outputId": "a52256ea-01ef-4d75-d076-a3ec42c7ec92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'super' object has no attribute '__sklearn_tags__'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-818e6afa789d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# model을 esimator에 집어 넣고 실험, \"cv=3\"은 3-Folde Cross Validation 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0mTarget\u001b[0m \u001b[0mrelative\u001b[0m \u001b[0mto\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclassification\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mregression\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0munsupervised\u001b[0m \u001b[0mlearning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m \u001b[0mof\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m             \u001b[0mParameters\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mis_classifier\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m   1235\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mis_regressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m     \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mis_regressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregressor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m     \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mis_regressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_tags.py\u001b[0m in \u001b[0;36mget_tags\u001b[0;34m(estimator)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m__sklearn_tags__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mReturns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0mMean\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'super' object has no attribute '__sklearn_tags__'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4. Test\n",
        "\n",
        " - Best Model Final Test\n",
        " - 검증을 통해서 채택한 Optimal Hyperparameter model에 test data 적용 : \"Accuracy\" 산출"
      ],
      "metadata": {
        "id": "bgZjAQykcLjk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HjbNaQv1bngh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}